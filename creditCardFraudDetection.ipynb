{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset imported from\n",
    "https://www.kaggle.com/mlg-ulb/creditcardfraud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Explorations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# load dataset\n",
    "fraud_df = pd.read_csv(\"creditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_df.shape\n",
    "#\"Dataset Shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
       "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
       "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount',\n",
       "       'Class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_df.columns\n",
    "#column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Unique values of target variable :- \n",
    "fraud_df['Class'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target variable Class has 0 and 1 values. Here\n",
    "\n",
    "0 for non-fraudulent transactions\n",
    "1 for fraudulent transactions\n",
    "Because we aim to find fraudulent transactions, the dataset's target value has a positive value for that. \n",
    "\n",
    "\n",
    "\n",
    "yeah, we have to check how many samples each target class is having."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of samples under each target value :- \n",
    "fraud_df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we have 284315 non-fraudulent transaction samples & 492 fraudulent transaction samples.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Card Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing is the process of cleaning the dataset. In this step, we will apply different methods to clean the raw data to feed more meaningful data for the modeling phase. This method includes\n",
    "\n",
    "Remove duplicates or irrelevant samples\n",
    "Update missing values with the most relevant values \n",
    "Convert one data type to another example, categorical to integers, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing irrelevant columns/features\n",
    "In our dataset, only one irrelevant or not useful feature id Time. So we can drop that feature from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11',\n",
       "       'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21',\n",
       "       'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount', 'Class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure which features are useful & which are not\n",
    "# we can remove irrelevant features\n",
    "fraud_df = fraud_df.drop(['Time'], axis=1)\n",
    "fraud_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking null or nan values \n",
    "We can check the datatypes of all features and, at the same time, the number of non-null values of all features by using info() of pandas. \n",
    "\n",
    "Null or nan values are nothing, but there is no value for that particular feature or attribute.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 30 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   V1      284807 non-null  float64\n",
      " 1   V2      284807 non-null  float64\n",
      " 2   V3      284807 non-null  float64\n",
      " 3   V4      284807 non-null  float64\n",
      " 4   V5      284807 non-null  float64\n",
      " 5   V6      284807 non-null  float64\n",
      " 6   V7      284807 non-null  float64\n",
      " 7   V8      284807 non-null  float64\n",
      " 8   V9      284807 non-null  float64\n",
      " 9   V10     284807 non-null  float64\n",
      " 10  V11     284807 non-null  float64\n",
      " 11  V12     284807 non-null  float64\n",
      " 12  V13     284807 non-null  float64\n",
      " 13  V14     284807 non-null  float64\n",
      " 14  V15     284807 non-null  float64\n",
      " 15  V16     284807 non-null  float64\n",
      " 16  V17     284807 non-null  float64\n",
      " 17  V18     284807 non-null  float64\n",
      " 18  V19     284807 non-null  float64\n",
      " 19  V20     284807 non-null  float64\n",
      " 20  V21     284807 non-null  float64\n",
      " 21  V22     284807 non-null  float64\n",
      " 22  V23     284807 non-null  float64\n",
      " 23  V24     284807 non-null  float64\n",
      " 24  V25     284807 non-null  float64\n",
      " 25  V26     284807 non-null  float64\n",
      " 26  V27     284807 non-null  float64\n",
      " 27  V28     284807 non-null  float64\n",
      " 28  Amount  284807 non-null  float64\n",
      " 29  Class   284807 non-null  int64  \n",
      "dtypes: float64(29), int64(1)\n",
      "memory usage: 65.2 MB\n"
     ]
    }
   ],
   "source": [
    "fraud_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the result of dataset info(); \n",
    "\n",
    "it provides all information about our dataset, such as \n",
    "\n",
    "Total number of samples or rows\n",
    "Column names\n",
    "Number of non-null values\n",
    "The data type of each column\n",
    "Our dataset doesn’t have any null values because the total number features are 284807 that ranges from 0-284806; all features have the same number of samples/rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #Data Transformation\n",
    "Except for the Amount column, all column’s values are within some range of values. So let's change the Amount columns values to a smaller range of numbers. \n",
    "\n",
    "We can simply do this process by using StandardScaler from the sklearn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    149.62\n",
       "1      2.69\n",
       "2    378.66\n",
       "3    123.50\n",
       "Name: Amount, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#few values of Amount column :- \n",
    "fraud_df['Amount'][0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the values of the Amount feature values are in high range compared to other feature values. \n",
    "\n",
    "We will change values within a smaller range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.244964\n",
       "1   -0.342475\n",
       "2    1.160686\n",
       "3    0.140534\n",
       "Name: norm_amount, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " #data preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "fraud_df['norm_amount'] = StandardScaler().fit_transform(\n",
    "fraud_df['Amount'].values.reshape(-1,1))\n",
    "fraud_df = fraud_df.drop(['Amount'], axis=1)\n",
    "fraud_df['norm_amount'][0:4]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scalar result is added as a new column with norm_amount name to the data frame after we drop the Amount column because there is no use with it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting dataset \n",
    "#Now we will take all independent columns (target column is dependent and the remaining all are independent columns to each other), as X and the target variable as y.\n",
    "\n",
    "\n",
    "## Features and target creations\n",
    "X = fraud_df.drop(['Class'], axis=1)\n",
    "y = fraud_df[['Class']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to split the whole dataset into train and test dataset. Training data is used at the time of building the model and a test dataset is used to evaluate trained models. \n",
    "\n",
    "By using the train_test_split method from the sklearn library we can do this process of splitting the dataset to train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85443, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# splitting dataset to train & test dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "X_train.shape\n",
    "X_test.shape\n",
    "y_train.shape\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Credit Card Fraud Detection using Machine Learning algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Credit card fraud detection is a classification problem. Target variable values of Classification problems have integer(0,1) or categorical values(fraud, non-fraud). The target variable of our dataset ‘Class’ has only two labels - 0 (non-fraudulent) and 1 (fraudulent)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree algorithm Implementation using python sklearn library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training starts........\n",
      "Model training completed\n",
      "Accuracy of model on test dataset :- 0.9992509626300574\n",
      "Confusion Matrix :- \n",
      " [[85266    30]\n",
      " [   34   113]]\n",
      "Classification Report :- \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85296\n",
      "           1       0.79      0.77      0.78       147\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.89      0.88      0.89     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Building decision tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def decision_tree_classification(X_train, y_train, X_test, y_test):\n",
    "    # initialize object for DecisionTreeClassifier class\n",
    "    dt_classifier = DecisionTreeClassifier()\n",
    "    # train model by using fit method\n",
    "    print(\"Model training starts........\")\n",
    "    dt_classifier.fit(X_train, y_train.values.ravel())\n",
    "    print(\"Model training completed\")\n",
    "    acc_score = dt_classifier.score(X_test, y_test)\n",
    "    print(f'Accuracy of model on test dataset :- {acc_score}')\n",
    "    # predict result using test dataset\n",
    "    y_pred = dt_classifier.predict(X_test)\n",
    "    # confusion matrix\n",
    "    print(f\"Confusion Matrix :- \\n {confusion_matrix(y_test, y_pred)}\")\n",
    "    # classification report for f1-score\n",
    "    print(f\"Classification Report :- \\n {classification_report(y_test, y_pred)}\")\n",
    "\n",
    "\n",
    "\n",
    "# calling decision_tree_classification method to train and evaluate model\n",
    "decision_tree_classification(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "our decision tree classification gives 99% accuracy on test data. \n",
    "\n",
    "But  f1-score on label 1 too less ?. \n",
    "\n",
    "\n",
    "\n",
    " the accuracy evaluation metric is not suitable for this problem,why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Card Fraud Detection with Random Forest Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as the above decision tree implementation, we use X_train and y_train dataset for training purposes and X_test for evaluation. Here we train the ensemble technique model of RandomForestClassifier from the sklearn. We can see the variations in the evaluation results.\n",
    "\n",
    "Random forest algorithm Implementation using sklearn library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training starts........\n",
      "Accuracy of model on test dataset :- 0.9994616293903538\n",
      "Confusion Matrix :- \n",
      " [[85289     7]\n",
      " [   39   108]]\n",
      "Classification Report :- \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85296\n",
      "           1       0.94      0.73      0.82       147\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.97      0.87      0.91     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Model with randomforest\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def random_forest_classifier(X_train, y_train, X_test, y_test):\n",
    "     # initialize object for DecisionTreeClassifier class\n",
    "     rf_classifier = RandomForestClassifier(n_estimators=50)\n",
    "     # train model by using fit method\n",
    "     print(\"Model training starts........\")\n",
    "     rf_classifier.fit(X_train, y_train.values.ravel())\n",
    "     acc_score = rf_classifier.score(X_test, y_test)\n",
    "     print(f'Accuracy of model on test dataset :- {acc_score}')\n",
    "     # predict result using test dataset\n",
    "     y_pred = rf_classifier.predict(X_test)\n",
    "     # confusion matrix\n",
    "     print(f\"Confusion Matrix :- \\n {confusion_matrix(y_test, y_pred)}\")\n",
    "     # classification report for f1-score\n",
    "     print(f\"Classification Report :- \\n {classification_report(y_test, y_pred)}\")\n",
    "\n",
    "\n",
    "# calling random_forest_classifier\n",
    "random_forest_classifier(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why Accuracy not suitable for Data Imbalance Problems?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will check our dataset and what are the best evaluation metrics for these kinds of problems.\n",
    "\n",
    "For this discussion, we have to remember two things that are previously discussed.\n",
    "\n",
    "The number of samples for each Class (target variable) value.\n",
    "Evaluation metrics at both the decision tree and random forest classification models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "fraud_df['Class'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the number of samples for Class-1 (fraudulent) less than the samples for class-0 (non-fraudulent). \n",
    "\n",
    "This kind of dataset is called unbalanced data. Which means one class label samples are  higher and dominating the other class label. \n",
    "\n",
    "For a balanced dataset, accuracy is suitable because we take the divided value of the correctly predicted samples count with the total number of samples for accuracy. \n",
    "\n",
    "Accuracy = number of correctly predicted samples / total number of samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use any of the below-mentioned metrics for unbalanced or skewed datasets.\n",
    "\n",
    "Recall\n",
    "Precision\n",
    "F1-score\n",
    "Area Under ROC curve.\n",
    "We can see the huge difference among different evaluation metrics for both classifications (decision tree & random forest) models. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Improvement Using Sampling Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Data sampling is the statistical method for selecting data points (here, the data point is a single row) from the whole dataset. In machine learning problems, there are many sampling techniques available.\n",
    "\n",
    "Here we take undersampling and oversampling strategies for handling imbalanced data.  \n",
    "\n",
    "What is this undersampling and oversampling?\n",
    "Let us take an example of a dataset that has nine samples. \n",
    "\n",
    "Six samples belong to class-0,\n",
    "Three samples belong to class-1\n",
    "Oversampling = 6 class-0 samples x  2 times of class-1 samples of 3\n",
    "\n",
    "Undersampling = 3 Class-1 samples x 3 samples from Class-0\n",
    "\n",
    "Here what we are trying to do is the number of samples of both target classes to be equal. \n",
    "\n",
    "In the oversampling technique, samples are repeated, and the dataset size is larger than the original dataset.\n",
    "\n",
    "In the undersampling technique, samples are not repeated, and the dataset size is less than the original dataset.\n",
    "\n",
    "Applying Sampling Techniques \n",
    "For undersampling techniques, we are checking the number of samples of both classes and selecting the smaller number and taking random samples from other class samples to create a new dataset.  \n",
    "\n",
    "The new dataset has an equal number of samples for both target classes.\n",
    "\n",
    "This is a whole process of undersampling, and now we are going to implement this entire process using python.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples for each class :- \n",
      " 0    284315\n",
      "1       492\n",
      "Name: Class, dtype: int64\n",
      "Non Fraudulent Numbers :- 284315\n",
      "Fraudulent Numbers :- 492\n"
     ]
    }
   ],
   "source": [
    "# Target class distribution\n",
    "class_val = fraud_df['Class'].value_counts()\n",
    "print(f\"Number of samples for each class :- \\n {class_val}\")\n",
    "non_fraud = class_val[0]\n",
    "fraud = class_val[1]\n",
    "print(f\"Non Fraudulent Numbers :- {non_fraud}\")\n",
    "print(f\"Fraudulent Numbers :- {fraud}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above is the target class distributions, now let's see how we can change this.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Equal both the target samples to the same level\n",
    "# take indexes of non fraudulent\n",
    "nonfraud_indexies = fraud_df[fraud_df.Class == 0].index\n",
    "fraud_indices = np.array(fraud_df[fraud_df['Class'] == 1].index)\n",
    "# take random samples from non fraudulent that are equal to fraudulent samples\n",
    "random_normal_indexies = np.random.choice(nonfraud_indexies, fraud, replace=False)\n",
    "random_normal_indexies = np.array(random_normal_indexies)\n",
    "# view raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here first, we take indexes of both classes and randomly choose Class-0 samples indexes that are equal to the number of Class-1 samples. \n",
    "\n",
    "In the below code snippet, Combine both classes indexes. Then we extract all features of gathered indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Equal both the target samples to the same level\n",
    "# take indexes of non fraudulent\n",
    "nonfraud_indexies = fraud_df[fraud_df.Class == 0].index\n",
    "fraud_indices = np.array(fraud_df[fraud_df['Class'] == 1].index)\n",
    "# take random samples from non fraudulent that are equal to fraudulent samples\n",
    "random_normal_indexies = np.random.choice(nonfraud_indexies, fraud, replace=False)\n",
    "random_normal_indexies = np.array(random_normal_indexies)\n",
    "\n",
    "\n",
    "## Undersampling techniques\n",
    "\n",
    "# concatenate both indices of fraud and non fraud\n",
    "under_sample_indices = np.concatenate([fraud_indices, random_normal_indexies])\n",
    "\n",
    "#extract all features from whole data for under sample indices only\n",
    "under_sample_data = fraud_df.iloc[under_sample_indices, :]\n",
    "\n",
    "# now we have to divide under sampling data to all features & target\n",
    "x_undersample_data = under_sample_data.drop(['Class'], axis=1)\n",
    "y_undersample_data = under_sample_data[['Class']]\n",
    "# now split dataset to train and test datasets as before\n",
    "X_train_sample, X_test_sample, y_train_sample, y_test_sample = train_test_split(\n",
    "x_undersample_data, y_undersample_data, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code first divides features and targets as x_undersample_data and y_undersample_data and then splits new undersample data into train and test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree classification after applying sampling techniques\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training start........\n",
      "Model training completed\n",
      "Accuracy of model on test dataset :- 0.9086294416243654\n",
      "Confusion Matrix :- \n",
      " [[92 14]\n",
      " [ 4 87]]\n",
      "Classification Report :- \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.87      0.91       106\n",
      "           1       0.86      0.96      0.91        91\n",
      "\n",
      "    accuracy                           0.91       197\n",
      "   macro avg       0.91      0.91      0.91       197\n",
      "weighted avg       0.91      0.91      0.91       197\n",
      "\n",
      "AROC score :- \n",
      " 0.9119842421729216\n"
     ]
    }
   ],
   "source": [
    "## DecisionTreeClassifier after applying undersampling technique\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def decision_tree_classification(X_train, y_train, X_test, y_test):\n",
    " # initialize object for DecisionTreeClassifier class\n",
    " dt_classifier = DecisionTreeClassifier()\n",
    " # train model by using fit method\n",
    " print(\"Model training start........\")\n",
    " dt_classifier.fit(X_train, y_train.values.ravel())\n",
    " print(\"Model training completed\")\n",
    " acc_score = dt_classifier.score(X_test, y_test)\n",
    " print(f'Accuracy of model on test dataset :- {acc_score}')\n",
    " # predict result using test dataset\n",
    " y_pred = dt_classifier.predict(X_test)\n",
    " # confusion matrix\n",
    " print(f\"Confusion Matrix :- \\n {confusion_matrix(y_test, y_pred)}\")\n",
    " # classification report for f1-score\n",
    " print(f\"Classification Report :- \\n {classification_report(y_test, y_pred)}\")\n",
    " print(f\"AROC score :- \\n {roc_auc_score(y_test, y_pred)}\")\n",
    "\n",
    "# calling decision tree classifier function \n",
    "decision_tree_classification(X_train_sample, y_train_sample, \n",
    "X_test_sample, y_test_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Tree Classifier after applying the sampling techniques\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training start........\n",
      "Accuracy of model on test dataset :- 0.9593908629441624\n",
      "Confusion Matrix :- \n",
      " [[103   3]\n",
      " [  5  86]]\n",
      "Classification Report :- \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96       106\n",
      "           1       0.97      0.95      0.96        91\n",
      "\n",
      "    accuracy                           0.96       197\n",
      "   macro avg       0.96      0.96      0.96       197\n",
      "weighted avg       0.96      0.96      0.96       197\n",
      "\n",
      "AROC score :- \n",
      " 0.9583765291312462\n"
     ]
    }
   ],
   "source": [
    "## RandomForestClassifier after apply the undersampling techniques\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def random_forest_classifier(X_train, y_train, X_test, y_test):\n",
    " # initialize object for DecisionTreeClassifier class\n",
    " rf_classifier = RandomForestClassifier(n_estimators=50)\n",
    " # train model by using fit method\n",
    " print(\"Model training start........\")\n",
    " rf_classifier.fit(X_train, y_train.values.ravel())\n",
    " acc_score = rf_classifier.score(X_test, y_test)\n",
    " print(f'Accuracy of model on test dataset :- {acc_score}')\n",
    " # predict result using test dataset\n",
    " y_pred = rf_classifier.predict(X_test)\n",
    " # confusion matrix\n",
    " print(f\"Confusion Matrix :- \\n {confusion_matrix(y_test, y_pred)}\")\n",
    " # classification report for f1-score\n",
    " print(f\"Classification Report :- \\n {classification_report(y_test, y_pred)}\")\n",
    " # area under roc curve\n",
    " print(f\"AROC score :- \\n {roc_auc_score(y_test, y_pred)}\")\n",
    "\n",
    "random_forest_classifier(X_train_sample, y_train_sample, X_test_sample, y_test_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case of, Random Forest Tree Classifier,the results of the F1-score for both target values are 95%, and the Area Under ROC curve is near to 1. \n",
    "so,Random Forest Tree  Algorithm works better here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
